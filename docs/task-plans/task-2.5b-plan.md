# Task 2.5b: LLM ì•ˆì •ì„± ê°•í™” - ì‹¤í–‰ ê³„íš

---

## ğŸ“‹ Meta

- **Task ID**: 2.5b
- **Taskëª…**: LLM ì•ˆì •ì„± ê°•í™”
- **ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„
- **ë‹´ë‹¹**: Backend
- **ì‘ì„±ì¼**: 2026-01-03
- **ìƒíƒœ**: Ready for Implementation (Task 2.5a ì§í›„ ì§„í–‰)
- **ë²„ì „**: 1.0.0

---

## 1. Executive Summary

### 1.1 ëª©í‘œ
Hallucination ë°©ì§€, íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬, ì¬ì‹œë„ ë¡œì§ì„ ì¶”ê°€í•˜ì—¬ LLM ë‹µë³€ ìƒì„±ì˜ ì•ˆì •ì„±ì„ ê°•í™”í•©ë‹ˆë‹¤.

### 1.2 í•µì‹¬ ìš”êµ¬ì‚¬í•­
- **ë³´ì•ˆ**: [HARD RULE] ê²€ìƒ‰ëœ ë¬¸ì„œë§Œ ì‚¬ìš©, ì¶œì²˜ ì—†ëŠ” ë‹µë³€ ê¸ˆì§€
- **ì•ˆì •ì„±**: 30ì´ˆ íƒ€ì„ì•„ì›ƒ, 3íšŒ ì¬ì‹œë„ (exponential backoff)
- **í’ˆì§ˆ**: Confidence threshold 0.5, Hallucination 0ê±´
- **ì„±ê³µ ê¸°ì¤€**: ì¶œì²˜ ì •í™•ë„ 100%, Hallucination ë°©ì§€ í…ŒìŠ¤íŠ¸ 100% í†µê³¼

### 1.3 ì„±ê³µ ê¸°ì¤€
- [ ] ê´€ë ¨ ë¬¸ì„œ ì—†ì„ ë•Œ Fallback ë©”ì‹œì§€ ë°˜í™˜
- [ ] Confidence < 0.5 ì‹œ Fallback ë©”ì‹œì§€ ë°˜í™˜
- [ ] LLM íƒ€ì„ì•„ì›ƒ ì‹œ ì¬ì‹œë„ â†’ Fallback
- [ ] ì¶œì²˜ ì—†ëŠ” ë‹µë³€ ê±°ë¶€
- [ ] Hallucination ë°©ì§€ í…ŒìŠ¤íŠ¸ 5ê°œ ì¼€ì´ìŠ¤ í†µê³¼

### 1.4 Why This Task Matters
**ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” RAG ì‹œìŠ¤í…œ**:
- **Hallucination ë°©ì§€**: ê±°ì§“ ì •ë³´ ìƒì„± ì°¨ë‹¨
- **ì‚¬ìš©ì ì‹ ë¢°**: í•­ìƒ ì¶œì²˜ê°€ ìˆëŠ” ë‹µë³€ë§Œ ì œê³µ
- **ì‹œìŠ¤í…œ ì•ˆì •ì„±**: LLM ì¥ì•  ì‹œì—ë„ ì„œë¹„ìŠ¤ ìœ ì§€

---

## 2. ì„ í–‰ ì¡°ê±´ ê²€ì¦

### 2.1 í™˜ê²½ ê²€ì¦
```bash
# Task 2.5a ì™„ë£Œ í™•ì¸
ls -la backend/app/services/rag_service.py
ls -la backend/app/services/llm/ollama_provider.py

# Tenacity ì„¤ì¹˜ í™•ì¸ (ì¬ì‹œë„ ë¡œì§)
python -c "import tenacity; print(tenacity.__version__)"
```

### 2.2 ì˜ì¡´ì„± í™•ì¸
- [x] **Task 2.5a**: RAGService ê¸°ë³¸ êµ¬í˜„ ì™„ë£Œ
- [x] **Task 2.3**: VectorSearchService ì™„ë£Œ
- [x] **requirements.txt**: tenacity (ì´ë¯¸ Task 1.8ì—ì„œ ì„¤ì¹˜ë¨)

---

## 3. ì•ˆì •ì„± ê°•í™” ì „ëµ

### 3.1 Hallucination ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜

```
ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
    â†“
ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ? â†’ Fallback: "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    â†“
ê´€ë ¨ë„ ì ìˆ˜ í™•ì¸
    â†“
í‰ê·  ê´€ë ¨ë„ < 0.5? â†’ Fallback: "ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    â†“
LLM ë‹µë³€ ìƒì„±
    â†“
ì¶œì²˜ ê²€ì¦ (ë‹µë³€ì— ì¶œì²˜ í¬í•¨?)
    â†“
ì¶œì²˜ ì—†ìŒ? â†’ ì¬ìƒì„± ë˜ëŠ” Fallback
    â†“
ìµœì¢… ë‹µë³€ ë°˜í™˜
```

### 3.2 íƒ€ì„ì•„ì›ƒ ë° ì¬ì‹œë„

```python
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    reraise=True
)
async def generate_with_timeout(prompt: str) -> str:
    """30ì´ˆ íƒ€ì„ì•„ì›ƒ + 3íšŒ ì¬ì‹œë„"""
    async with timeout(30):
        return await llm_provider.generate(prompt)
```

---

## 4. êµ¬í˜„ ë‹¨ê³„ë³„ ìƒì„¸ ê³„íš

### 4.1 Step 1: Hallucination ë°©ì§€ ë¡œì§ (90ë¶„)

#### ì‘ì—… ë‚´ìš©
**`backend/app/services/rag_service.py` ê°•í™”**:

```python
from typing import List, Optional
import re


class RAGService:
    # ... ê¸°ì¡´ ì½”ë“œ ...

    CONFIDENCE_THRESHOLD = 0.5  # ìµœì†Œ ì‹ ë¢°ë„
    FALLBACK_NO_DOCUMENTS = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    FALLBACK_LOW_CONFIDENCE = "ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
    FALLBACK_NO_SOURCE = "ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."

    def generate_answer(
        self,
        query: str,
        search_results: List[SearchResult]
    ) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë‹µë³€ ìƒì„± (Hallucination ë°©ì§€)

        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            search_results: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼

        Returns:
            str: ìƒì„±ëœ ë‹µë³€ (Fallback í¬í•¨)
        """
        # [STEP 1] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ â†’ Fallback
        if not search_results:
            logger.warning("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, Fallback ë°˜í™˜")
            return self.FALLBACK_NO_DOCUMENTS

        # [STEP 2] ê´€ë ¨ë„ ì ìˆ˜ í™•ì¸
        avg_relevance = sum(r.relevance_score for r in search_results) / len(search_results)

        if avg_relevance < self.CONFIDENCE_THRESHOLD:
            logger.warning(
                f"ë‚®ì€ ê´€ë ¨ë„ (avg={avg_relevance:.3f}), Fallback ë°˜í™˜"
            )
            return self.FALLBACK_LOW_CONFIDENCE

        # [STEP 3] Context êµ¬ì„±
        context = self._build_context(search_results)

        # [STEP 4] í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = RAG_PROMPT_TEMPLATE.format(
            context=context,
            query=query
        )

        # [STEP 5] LLM ë‹µë³€ ìƒì„± (íƒ€ì„ì•„ì›ƒ + ì¬ì‹œë„)
        try:
            answer = self._generate_with_retry(prompt)

            # [STEP 6] ì¶œì²˜ ê²€ì¦
            if not self._has_source_citation(answer):
                logger.error(
                    "ì¶œì²˜ ë¯¸í¬í•¨ ë‹µë³€ ê±°ë¶€: answer='{answer[:100]}...'"
                )
                return self.FALLBACK_NO_SOURCE

            logger.info("RAG ë‹µë³€ ìƒì„± ì„±ê³µ (ì¶œì²˜ ê²€ì¦ ì™„ë£Œ)")
            return answer

        except Exception as e:
            logger.error(f"RAG ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return self.FALLBACK_NO_SOURCE

    def _has_source_citation(self, answer: str) -> bool:
        """
        ë‹µë³€ì— ì¶œì²˜ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

        Args:
            answer: ìƒì„±ëœ ë‹µë³€

        Returns:
            bool: ì¶œì²˜ í¬í•¨ ì—¬ë¶€
        """
        # ì¶œì²˜ íŒ¨í„´: "ë¬¸ì„œ", "ì¶œì²˜", "ê·œì •", "ì— ë”°ë¥´ë©´" ë“±
        citation_patterns = [
            r"ë¬¸ì„œ",
            r"ì¶œì²˜",
            r"ê·œì •",
            r"ì— ë”°ë¥´ë©´",
            r"ë”°ë¼ì„œ",
            r"\[ë¬¸ì„œ \d+\]"  # [ë¬¸ì„œ 1], [ë¬¸ì„œ 2] ë“±
        ]

        for pattern in citation_patterns:
            if re.search(pattern, answer):
                return True

        logger.warning(f"ì¶œì²˜ ë¯¸í¬í•¨: answer='{answer[:100]}...'")
        return False
```

---

### 4.2 Step 2: íƒ€ì„ì•„ì›ƒ ë° ì¬ì‹œë„ ë¡œì§ (60ë¶„)

#### ì‘ì—… ë‚´ìš©
**`backend/app/services/rag_service.py` ì¬ì‹œë„ ë¡œì§ ì¶”ê°€**:

```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)
import asyncio


class RAGService:
    # ... ê¸°ì¡´ ì½”ë“œ ...

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry_if_exception_type=TimeoutError,
        reraise=True
    )
    def _generate_with_retry(self, prompt: str) -> str:
        """
        ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ LLM ë‹µë³€ ìƒì„±

        Args:
            prompt: í”„ë¡¬í”„íŠ¸

        Returns:
            str: ìƒì„±ëœ ë‹µë³€

        Raises:
            TimeoutError: 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            ValueError: LLM ìƒì„± ì‹¤íŒ¨
        """
        logger.info("LLM ë‹µë³€ ìƒì„± ì‹œì‘ (íƒ€ì„ì•„ì›ƒ: 30ì´ˆ)")

        try:
            # 30ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            import signal

            def timeout_handler(signum, frame):
                raise TimeoutError("LLM ë‹µë³€ ìƒì„± íƒ€ì„ì•„ì›ƒ (30ì´ˆ)")

            # Timeout ì„¤ì •
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(30)

            try:
                answer = self.llm_provider.generate(prompt)
                signal.alarm(0)  # íƒ€ì„ì•„ì›ƒ í•´ì œ
                return answer

            except TimeoutError:
                signal.alarm(0)
                logger.warning("LLM íƒ€ì„ì•„ì›ƒ ë°œìƒ, ì¬ì‹œë„...")
                raise

        except Exception as e:
            logger.error(f"LLM ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            raise ValueError(f"LLM ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
```

---

### 4.3 Step 3: Fallback ì „ëµ (60ë¶„)

#### ì‘ì—… ë‚´ìš©
**Fallback ì‘ë‹µ í˜•ì‹ í‘œì¤€í™”**:

```python
class RAGService:
    # ... ê¸°ì¡´ ì½”ë“œ ...

    def generate_answer_with_fallback(
        self,
        query: str,
        search_results: List[SearchResult]
    ) -> dict:
        """
        Fallback ì •ë³´ë¥¼ í¬í•¨í•œ ë‹µë³€ ìƒì„±

        Returns:
            dict: {
                "answer": str,
                "is_fallback": bool,
                "fallback_reason": Optional[str],
                "search_results": List[SearchResult]
            }
        """
        # ë‹µë³€ ìƒì„± ì‹œë„
        answer = self.generate_answer(query, search_results)

        # Fallback ì—¬ë¶€ í™•ì¸
        is_fallback = answer in [
            self.FALLBACK_NO_DOCUMENTS,
            self.FALLBACK_LOW_CONFIDENCE,
            self.FALLBACK_NO_SOURCE
        ]

        fallback_reason = None
        if is_fallback:
            if answer == self.FALLBACK_NO_DOCUMENTS:
                fallback_reason = "no_documents"
            elif answer == self.FALLBACK_LOW_CONFIDENCE:
                fallback_reason = "low_confidence"
            elif answer == self.FALLBACK_NO_SOURCE:
                fallback_reason = "no_source_citation"

        return {
            "answer": answer,
            "is_fallback": is_fallback,
            "fallback_reason": fallback_reason,
            "search_results": search_results if is_fallback else []
        }
```

---

### 4.4 Step 4: í†µí•© í…ŒìŠ¤íŠ¸ (60ë¶„)

#### ì‘ì—… ë‚´ìš©
**`backend/tests/test_hallucination_prevention.py` ì‘ì„±**:

```python
import pytest
from app.services.rag_service import RAGService
from app.services.vector_search import SearchResult


def test_no_search_results_fallback():
    """TC01: ê²€ìƒ‰ ê²°ê³¼ ì—†ì„ ë•Œ Fallback"""
    rag_service = RAGService()

    answer = rag_service.generate_answer(
        query="ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë¬¸ì„œ ì§ˆë¬¸",
        search_results=[]
    )

    assert "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in answer


def test_low_confidence_fallback():
    """TC02: ë‚®ì€ ê´€ë ¨ë„ ì ìˆ˜ â†’ Fallback"""
    rag_service = RAGService()

    # ê´€ë ¨ë„ 0.3ì¸ ê²°ê³¼ (threshold 0.5 ë¯¸ë§Œ)
    low_confidence_results = [
        SearchResult(
            document_id="doc_001",
            chunk_index=0,
            content="ê´€ë ¨ ì—†ëŠ” ë‚´ìš©",
            page_number=1,
            relevance_score=0.3,
            metadata={}
        )
    ]

    answer = rag_service.generate_answer(
        query="í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
        search_results=low_confidence_results
    )

    assert "ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in answer


def test_answer_with_source_citation():
    """TC03: ì¶œì²˜ê°€ í¬í•¨ëœ ë‹µë³€ ê²€ì¦"""
    rag_service = RAGService()

    # Mock: ì¶œì²˜ í¬í•¨ ë‹µë³€
    answer = "íœ´ê°€ ê·œì • ë¬¸ì„œì— ë”°ë¥´ë©´ ì—°ì°¨ëŠ” ì…ì‚¬ì¼ ê¸°ì¤€ 1ë…„ í›„ë¶€í„° ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."

    has_source = rag_service._has_source_citation(answer)

    assert has_source is True


def test_answer_without_source_rejected():
    """TC04: ì¶œì²˜ ì—†ëŠ” ë‹µë³€ ê±°ë¶€"""
    rag_service = RAGService()

    # Mock: ì¶œì²˜ ì—†ëŠ” ë‹µë³€
    answer = "ì—°ì°¨ëŠ” 1ë…„ í›„ë¶€í„° ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."

    has_source = rag_service._has_source_citation(answer)

    assert has_source is False


def test_timeout_retry_mechanism():
    """TC05: íƒ€ì„ì•„ì›ƒ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜"""
    # TODO: Mock LLM Providerë¡œ íƒ€ì„ì•„ì›ƒ ì‹œë®¬ë ˆì´ì…˜
    pass
```

---

## 5. í…ŒìŠ¤íŠ¸ ê³„íš

### 5.1 Hallucination ë°©ì§€ í…ŒìŠ¤íŠ¸ (5ê°œ)

```bash
pytest backend/tests/test_hallucination_prevention.py -v
# ì˜ˆìƒ: 5 passed
```

### 5.2 í†µí•© í…ŒìŠ¤íŠ¸

```bash
pytest backend/tests/integration/test_rag_stability.py -v
# ì˜ˆìƒ: 5 passed (End-to-End ì•ˆì •ì„± ê²€ì¦)
```

---

## 6. ê²€ì¦ ê¸°ì¤€

### 6.1 í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ê²€ìƒ‰ ê²°ê³¼ ì—†ì„ ë•Œ Fallback ë°˜í™˜
- [ ] Confidence < 0.5 ì‹œ Fallback ë°˜í™˜
- [ ] LLM íƒ€ì„ì•„ì›ƒ ì‹œ ì¬ì‹œë„ (3íšŒ)
- [ ] ì¶œì²˜ ì—†ëŠ” ë‹µë³€ ê±°ë¶€
- [ ] Hallucination ë°©ì§€ í…ŒìŠ¤íŠ¸ 5ê°œ í†µê³¼
- [ ] íƒ€ì„ì•„ì›ƒ 30ì´ˆ ì´ë‚´ ì‘ë‹µ

### 6.2 í’ˆì§ˆ ê¸°ì¤€

- [ ] ì¶œì²˜ ì •í™•ë„ 100% (ëª¨ë“  ë‹µë³€ì— ì¶œì²˜ í¬í•¨)
- [ ] Hallucination 0ê±´

---

## 7. ì¶œë ¥ë¬¼

### 7.1 ìƒì„±ë  íŒŒì¼

1. `backend/tests/test_hallucination_prevention.py` - Hallucination ë°©ì§€ í…ŒìŠ¤íŠ¸ (5ê°œ)
2. `backend/tests/integration/test_rag_stability.py` - í†µí•© í…ŒìŠ¤íŠ¸

### 7.2 ìˆ˜ì •ë  íŒŒì¼

1. `backend/app/services/rag_service.py` - ì•ˆì •ì„± ê°•í™” ë¡œì§ ì¶”ê°€

---

## 8. ì°¸ê³  ë¬¸ì„œ

- Task Breakdown: `docs/tasks/task-breakdown.md`
- Task 2.5a Plan: `docs/task-plans/task-2.5a-plan.md`
- Hallucination Prevention: https://arxiv.org/abs/2305.14251

---

**ì‘ì„±ì**: Claude Code (Sonnet 4.5)
**ì‘ì„±ì¼**: 2026-01-03
