# Task 2.3: ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„ - ì‹¤í–‰ ê³„íš

---

## ğŸ“‹ Meta

- **Task ID**: 2.3
- **Taskëª…**: ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„
- **ì˜ˆìƒ ì‹œê°„**: 6ì‹œê°„
- **ë‹´ë‹¹**: Backend
- **ì‘ì„±ì¼**: 2026-01-03
- **ìƒíƒœ**: Ready for Implementation
- **ë²„ì „**: 1.0.0

---

## 1. Executive Summary

### 1.1 ëª©í‘œ
Milvus ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ êµ¬í˜„í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ê´€ë ¨ëœ ë¬¸ì„œ ì²­í¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

### 1.2 í•µì‹¬ ìš”êµ¬ì‚¬í•­
- **ê¸°ëŠ¥**: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±, Milvus COSINE ìœ ì‚¬ë„ ê²€ìƒ‰, ìƒìœ„ 5ê°œ ê²°ê³¼ ë°˜í™˜
- **ì„±ëŠ¥**: [HARD RULE] P95 < 1ì´ˆ (95%ì˜ ê²€ìƒ‰ì´ 1ì´ˆ ì´ë‚´ ì™„ë£Œ)
- **í’ˆì§ˆ**: ê´€ë ¨ë„ ì ìˆ˜ 0.7 ì´ìƒ ê²°ê³¼ë§Œ ë°˜í™˜
- **ì•ˆì •ì„±**: ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ (3íšŒ)

### 1.3 ì„±ê³µ ê¸°ì¤€
- [ ] ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì„±ê³µ (768ì°¨ì›)
- [ ] Milvus ê²€ìƒ‰ ì„±ê³µ (ìƒìœ„ 5ê°œ ê²°ê³¼)
- [ ] P95 ê²€ìƒ‰ ì‹œê°„ < 1ì´ˆ
- [ ] ê´€ë ¨ë„ ì ìˆ˜ ì •ê·œí™” (0-1)
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 10ê°œ ì¼€ì´ìŠ¤ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ 10ê°œ ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼

### 1.4 Why This Task Matters
**RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ ì—”ì§„**:
- **ê²€ìƒ‰ í’ˆì§ˆ**: ì •í™•í•œ ë¬¸ì„œ ê²€ìƒ‰ì´ ë‹µë³€ í’ˆì§ˆ ê²°ì •
- **ì‚¬ìš©ì ê²½í—˜**: ë¹ ë¥¸ ê²€ìƒ‰ ì†ë„ë¡œ ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”
- **í™•ì¥ì„±**: ìˆ˜ì‹­ë§Œ ë¬¸ì„œì—ì„œë„ 1ì´ˆ ì´ë‚´ ê²€ìƒ‰

---

## 2. ì„ í–‰ ì¡°ê±´ ê²€ì¦

### 2.1 í™˜ê²½ ê²€ì¦
```bash
# Task 1.8 ì™„ë£Œ í™•ì¸ (ì„ë² ë”© ì„œë¹„ìŠ¤)
ls -la backend/app/services/embedding_service.py

# Task 1.3 ì™„ë£Œ í™•ì¸ (Milvus Collection)
python -c "from pymilvus import utility; print(utility.list_collections())"

# Ollama nomic-embed-text ëª¨ë¸ í™•ì¸
ollama list | grep nomic-embed-text
```

### 2.2 ì˜ì¡´ì„± í™•ì¸
- [x] **Task 1.3**: Milvus Collection ìƒì„± ì™„ë£Œ (documents)
- [x] **Task 1.4**: Ollama nomic-embed-text ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
- [x] **Task 1.8**: OllamaEmbeddingService êµ¬í˜„ ì™„ë£Œ
- [x] **Task 2.1**: FastAPI ê¸°ë³¸ êµ¬ì¡° ì™„ë£Œ
- [x] **Task 2.2**: ê²€ìƒ‰ì–´ ê²€ì¦ ì™„ë£Œ

---

## 3. ê¸°ìˆ  ìŠ¤íƒ ë° ì„¤ê³„

### 3.1 Milvus ê²€ìƒ‰ íŒŒë¼ë¯¸í„°

**ì„ íƒí•œ ì„¤ì •**:
```python
search_params = {
    "metric_type": "COSINE",  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ê°ë„ ê¸°ë°˜)
    "params": {"ef": 64}      # HNSW ê²€ìƒ‰ ì •í™•ë„ íŒŒë¼ë¯¸í„°
}
```

**ì„ íƒ ì´ìœ **:
- **COSINE**: í…ìŠ¤íŠ¸ ì„ë² ë”©ì— ê°€ì¥ ì í•© (ë°©í–¥ë§Œ ê³ ë ¤)
- **ef=64**: ì •í™•ë„ì™€ ì†ë„ ê· í˜• (ê¸°ë³¸ê°’ 10ë³´ë‹¤ ë†’ìŒ)

### 3.2 ê²€ìƒ‰ í”Œë¡œìš°

```
ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥
    â†“
1. ê²€ìƒ‰ì–´ ì„ë² ë”© ìƒì„± (OllamaEmbeddingService)
    â†“
2. Milvus ë²¡í„° ê²€ìƒ‰ (COSINE, top_k=5)
    â†“
3. ê´€ë ¨ë„ ì ìˆ˜ í•„í„°ë§ (â‰¥ 0.7)
    â†“
4. ê²°ê³¼ ì •ê·œí™” ë° ì •ë ¬
    â†“
ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜ (List[DocumentChunk])
```

---

## 4. êµ¬í˜„ ë‹¨ê³„ë³„ ìƒì„¸ ê³„íš

### 4.1 Step 1: ì¿¼ë¦¬ ì„ë² ë”© ì„œë¹„ìŠ¤ í™•ì¥ (90ë¶„)

#### ì‘ì—… ë‚´ìš©
ê¸°ì¡´ `OllamaEmbeddingService`ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜, ê²€ìƒ‰ ì „ìš© ë©”ì„œë“œ ì¶”ê°€

**`backend/app/services/embedding_service.py` í™•ì¥**:

```python
class OllamaEmbeddingService:
    # ... ê¸°ì¡´ ì½”ë“œ ...

    def embed_query(self, query: str) -> List[float]:
        """
        ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±

        Args:
            query: ê²€ìƒ‰ì–´ (ì´ë¯¸ ê²€ì¦ ì™„ë£Œ)

        Returns:
            List[float]: 768ì°¨ì› ì„ë² ë”© ë²¡í„°

        Raises:
            EmbeddingServiceError: ì„ë² ë”© ìƒì„± ì‹¤íŒ¨
        """
        logger.info(f"ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±: '{query[:50]}...'")

        try:
            embedding = self.embed_text(query)

            logger.info(
                f"ì„ë² ë”© ìƒì„± ì„±ê³µ: dimension={len(embedding)}, "
                f"query_length={len(query)}"
            )

            return embedding

        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            raise EmbeddingServiceError(f"ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨: {e}")
```

#### ê²€ì¦
```python
# ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸
embedding_service = OllamaEmbeddingService()
query_embedding = embedding_service.embed_query("ì—°ì°¨ ì‚¬ìš© ë°©ë²•")
assert len(query_embedding) == 768
```

---

### 4.2 Step 2: Milvus ë²¡í„° ê²€ìƒ‰ ë¡œì§ (120ë¶„)

#### ì‘ì—… ë‚´ìš©
`backend/app/services/vector_search.py` ì‘ì„±:

```python
from typing import List, Optional
from dataclasses import dataclass
from pymilvus import Collection
import logging

from app.db.milvus_client import get_milvus_collection
from app.services.embedding_service import OllamaEmbeddingService

logger = logging.getLogger(__name__)


@dataclass
class SearchResult:
    """ë²¡í„° ê²€ìƒ‰ ê²°ê³¼"""
    document_id: str
    chunk_index: int
    content: str
    page_number: Optional[int]
    relevance_score: float  # 0-1 ì •ê·œí™”ëœ ì ìˆ˜
    metadata: dict


class VectorSearchService:
    """Milvus ë²¡í„° ê²€ìƒ‰ ì„œë¹„ìŠ¤"""

    def __init__(
        self,
        collection_name: str = "documents",
        embedding_service: Optional[OllamaEmbeddingService] = None
    ):
        self.collection_name = collection_name
        self.embedding_service = embedding_service or OllamaEmbeddingService()
        self.collection: Optional[Collection] = None

        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        self.search_params = {
            "metric_type": "COSINE",
            "params": {"ef": 64}
        }
        self.relevance_threshold = 0.7  # ìµœì†Œ ê´€ë ¨ë„ ì ìˆ˜

        logger.info(
            f"VectorSearchService ì´ˆê¸°í™”: collection={collection_name}, "
            f"threshold={self.relevance_threshold}"
        )

    def _ensure_collection(self):
        """Collection ë¡œë“œ (lazy loading)"""
        if self.collection is None:
            self.collection = get_milvus_collection(self.collection_name)
            logger.info(f"Milvus Collection '{self.collection_name}' ë¡œë“œ ì™„ë£Œ")

    def search(
        self,
        query: str,
        top_k: int = 5,
        filter_expr: Optional[str] = None
    ) -> List[SearchResult]:
        """
        ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰

        Args:
            query: ê²€ìƒ‰ì–´
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            filter_expr: Milvus í•„í„° í‘œí˜„ì‹ (ì„ íƒì , Task 2.4ì—ì„œ ì‚¬ìš©)

        Returns:
            List[SearchResult]: ê²€ìƒ‰ ê²°ê³¼ (ê´€ë ¨ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬)

        Raises:
            ValueError: Collectionì´ ì—†ê±°ë‚˜ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ
        """
        self._ensure_collection()

        # Step 1: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        logger.info(f"ê²€ìƒ‰ ì‹œì‘: query='{query[:50]}...', top_k={top_k}")
        query_embedding = self.embedding_service.embed_query(query)

        # Step 2: Milvus ê²€ìƒ‰ ì‹¤í–‰
        try:
            search_results = self.collection.search(
                data=[query_embedding],
                anns_field="embedding",
                param=self.search_params,
                limit=top_k,
                expr=filter_expr,
                output_fields=[
                    "document_id",
                    "chunk_index",
                    "content",
                    "page_number",
                    "metadata"
                ]
            )

            # Step 3: ê²°ê³¼ íŒŒì‹± ë° í•„í„°ë§
            results = self._parse_results(search_results[0])

            logger.info(
                f"ê²€ìƒ‰ ì™„ë£Œ: found={len(results)}, "
                f"avg_score={sum(r.relevance_score for r in results) / len(results) if results else 0:.3f}"
            )

            return results

        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            raise ValueError(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    def _parse_results(self, raw_results) -> List[SearchResult]:
        """
        Milvus ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± ë° í•„í„°ë§

        Args:
            raw_results: Milvus SearchResult ê°ì²´

        Returns:
            List[SearchResult]: íŒŒì‹±ëœ ê²€ìƒ‰ ê²°ê³¼
        """
        results = []

        for hit in raw_results:
            # COSINE ìœ ì‚¬ë„: -1 ~ 1 â†’ 0 ~ 1ë¡œ ì •ê·œí™”
            normalized_score = (hit.score + 1) / 2

            # ê´€ë ¨ë„ ì ìˆ˜ í•„í„°ë§
            if normalized_score < self.relevance_threshold:
                logger.debug(
                    f"ë‚®ì€ ê´€ë ¨ë„ë¡œ ì œì™¸: score={normalized_score:.3f}, "
                    f"content='{hit.entity.get('content', '')[:50]}...'"
                )
                continue

            result = SearchResult(
                document_id=hit.entity.get("document_id"),
                chunk_index=hit.entity.get("chunk_index"),
                content=hit.entity.get("content"),
                page_number=hit.entity.get("page_number"),
                relevance_score=normalized_score,
                metadata=hit.entity.get("metadata", {})
            )

            results.append(result)

        # ê´€ë ¨ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ì´ë¯¸ ì •ë ¬ë˜ì–´ ìˆì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ)
        results.sort(key=lambda r: r.relevance_score, reverse=True)

        return results
```

---

### 4.3 Step 3: ê²°ê³¼ í›„ì²˜ë¦¬ ë° í†µí•© (60ë¶„)

#### ì‘ì—… ë‚´ìš©
ê²€ìƒ‰ ê²°ê³¼ë¥¼ API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

**`backend/app/services/search_service.py` ì‘ì„±**:

```python
from typing import List
from app.schemas.search import DocumentSource
from app.services.vector_search import VectorSearchService, SearchResult
import logging

logger = logging.getLogger(__name__)


class SearchService:
    """í†µí•© ê²€ìƒ‰ ì„œë¹„ìŠ¤ (Task 2.3-2.6ì—ì„œ ì ì§„ì  ì™„ì„±)"""

    def __init__(self):
        self.vector_search = VectorSearchService()

    def search_documents(
        self,
        query: str,
        limit: int = 5,
        user_id: Optional[str] = None
    ) -> List[DocumentSource]:
        """
        ë¬¸ì„œ ê²€ìƒ‰ (Task 2.3 ë²„ì „: ë²¡í„° ê²€ìƒ‰ë§Œ)

        Args:
            query: ê²€ìƒ‰ì–´
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            user_id: ì‚¬ìš©ì ID (Task 2.4ì—ì„œ ì‚¬ìš©)

        Returns:
            List[DocumentSource]: ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œì²˜ ë¦¬ìŠ¤íŠ¸
        """
        # Step 1: ë²¡í„° ê²€ìƒ‰
        search_results = self.vector_search.search(query, top_k=limit)

        # Step 2: DocumentSource ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜
        sources = [
            DocumentSource(
                document_id=result.document_id,
                document_title=result.metadata.get("document_title", "Unknown"),
                document_source=result.metadata.get("document_source", "Unknown"),
                chunk_content=result.content,
                page_number=result.page_number,
                relevance_score=result.relevance_score
            )
            for result in search_results
        ]

        logger.info(f"ê²€ìƒ‰ ì™„ë£Œ: query='{query}', results={len(sources)}")

        return sources
```

---

### 4.4 Step 4: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ìµœì í™” (60ë¶„)

#### ì„±ëŠ¥ ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸

**`backend/tests/performance/test_search_performance.py`**:

```python
import time
import statistics
from app.services.vector_search import VectorSearchService

def test_search_performance():
    """100íšŒ ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •"""
    search_service = VectorSearchService()

    queries = [
        "ì—°ì°¨ ì‚¬ìš© ë°©ë²•",
        "ê¸‰ì—¬ ì§€ê¸‰ì¼",
        "íœ´ê°€ ì‹ ì²­ ì ˆì°¨",
        "íšŒì˜ì‹¤ ì˜ˆì•½",
        "ë³µë¦¬í›„ìƒ ì œë„"
    ] * 20  # 100ê°œ ì¿¼ë¦¬

    response_times = []

    for query in queries:
        start_time = time.time()
        results = search_service.search(query, top_k=5)
        elapsed_ms = (time.time() - start_time) * 1000
        response_times.append(elapsed_ms)

    # í†µê³„ ê³„ì‚°
    p50 = statistics.median(response_times)
    p95 = statistics.quantiles(response_times, n=20)[18]  # 95th percentile
    p99 = statistics.quantiles(response_times, n=100)[98]  # 99th percentile

    print(f"ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì • (100íšŒ):")
    print(f"  P50: {p50:.2f}ms")
    print(f"  P95: {p95:.2f}ms")
    print(f"  P99: {p99:.2f}ms")

    # [HARD RULE] P95 < 1000ms ê²€ì¦
    assert p95 < 1000, f"P95 ì„±ëŠ¥ ëª©í‘œ ë¯¸ë‹¬: {p95:.2f}ms"
```

---

## 5. í…ŒìŠ¤íŠ¸ ê³„íš

### 5.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (10ê°œ ì¼€ì´ìŠ¤)

**`backend/tests/test_vector_search.py`**:

```python
import pytest
from app.services.vector_search import VectorSearchService

def test_vector_search_initialization():
    """TC01: VectorSearchService ì´ˆê¸°í™”"""
    service = VectorSearchService()
    assert service.collection_name == "documents"
    assert service.relevance_threshold == 0.7

def test_search_returns_results():
    """TC02: ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜"""
    service = VectorSearchService()
    results = service.search("ì—°ì°¨ ì‚¬ìš© ë°©ë²•", top_k=5)

    assert isinstance(results, list)
    assert len(results) <= 5

def test_search_result_structure():
    """TC03: ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡° ê²€ì¦"""
    service = VectorSearchService()
    results = service.search("ê¸‰ì—¬", top_k=5)

    if results:
        result = results[0]
        assert hasattr(result, 'document_id')
        assert hasattr(result, 'content')
        assert hasattr(result, 'relevance_score')
        assert 0 <= result.relevance_score <= 1

def test_relevance_score_threshold():
    """TC04: ê´€ë ¨ë„ ì ìˆ˜ í•„í„°ë§ (â‰¥ 0.7)"""
    service = VectorSearchService()
    results = service.search("test query", top_k=10)

    for result in results:
        assert result.relevance_score >= 0.7

def test_results_sorted_by_relevance():
    """TC05: ê²°ê³¼ ê´€ë ¨ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬"""
    service = VectorSearchService()
    results = service.search("ì—°ì°¨", top_k=5)

    if len(results) > 1:
        for i in range(len(results) - 1):
            assert results[i].relevance_score >= results[i + 1].relevance_score

# ... 5ê°œ ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
```

### 5.2 í†µí•© í…ŒìŠ¤íŠ¸ (10ê°œ ì‹œë‚˜ë¦¬ì˜¤)

**`backend/tests/integration/test_search_integration.py`**:

```python
def test_end_to_end_search():
    """TC01: End-to-End ê²€ìƒ‰ í”Œë¡œìš°"""
    from app.services.search_service import SearchService

    service = SearchService()
    sources = service.search_documents("ì—°ì°¨ ì‚¬ìš© ë°©ë²•", limit=5)

    assert len(sources) > 0
    assert sources[0].relevance_score >= 0.7
    assert sources[0].document_id is not None
```

### 5.3 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
pytest backend/tests/performance/test_search_performance.py -v -s
# ì˜ˆìƒ: P95 < 1000ms
```

---

## 6. ê²€ì¦ ê¸°ì¤€

### 6.1 í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì„±ê³µ (768ì°¨ì›)
- [ ] Milvus ê²€ìƒ‰ ì„±ê³µ (ìƒìœ„ 5ê°œ)
- [ ] ê´€ë ¨ë„ ì ìˆ˜ ì •ê·œí™” (0-1)
- [ ] ê´€ë ¨ë„ ì ìˆ˜ í•„í„°ë§ (â‰¥ 0.7)
- [ ] ê²°ê³¼ ê´€ë ¨ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 10ê°œ ì¼€ì´ìŠ¤ í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ 10ê°œ ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼
- [ ] **P95 < 1ì´ˆ** (ì„±ëŠ¥ ëª©í‘œ)

### 6.2 í’ˆì§ˆ ê¸°ì¤€

- [ ] ì½”ë“œ ì»¤ë²„ë¦¬ì§€ â‰¥ 90%
- [ ] ì—ëŸ¬ ë¡œê¹… ëª…í™•
- [ ] Collection ë¡œë“œ lazy loading
- [ ] ì¬ì‹œë„ ë¡œì§ (ì„ íƒì )

---

## 7. ì¶œë ¥ë¬¼

### 7.1 ìƒì„±ë  íŒŒì¼

1. `backend/app/services/vector_search.py` (VectorSearchService)
2. `backend/app/services/search_service.py` (í†µí•© ì„œë¹„ìŠ¤ - Task 2.3 ë²„ì „)
3. `backend/tests/test_vector_search.py` (ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 10ê°œ)
4. `backend/tests/integration/test_search_integration.py` (í†µí•© í…ŒìŠ¤íŠ¸)
5. `backend/tests/performance/test_search_performance.py` (ì„±ëŠ¥ í…ŒìŠ¤íŠ¸)

### 7.2 ìˆ˜ì •ë  íŒŒì¼

1. `backend/app/services/embedding_service.py` - `embed_query()` ë©”ì„œë“œ ì¶”ê°€
2. `backend/app/routers/search.py` - SearchService í†µí•© (Task 2.6ì—ì„œ ì™„ì„±)

---

## 8. ì°¸ê³  ë¬¸ì„œ

- Task Breakdown: `docs/tasks/task-breakdown.md`
- Task 1.8 Completion: `logs/task-1.8-20260102-204612.md`
- Milvus Documentation: https://milvus.io/docs
- HNSW Algorithm: https://arxiv.org/abs/1603.09320

---

**ì‘ì„±ì**: Claude Code (Sonnet 4.5)
**ì‘ì„±ì¼**: 2026-01-03
