# Task 4.3c ì‹¤í–‰ ê³„íš: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

## ğŸ“‹ ì‘ì—… ì •ë³´
- **Task ID**: 4.3c
- **Taskëª…**: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- **ì˜ˆìƒ ì‹œê°„**: 3ì‹œê°„
- **ë‹´ë‹¹**: Backend + Infrastructure
- **ì˜ì¡´ì„±**: Task 2.9 (ì„±ëŠ¥ ìµœì í™” ë° ë¡œê¹…)
- **GitHub Issue**: #34

---

## ğŸ¯ ì‘ì—… ëª©í‘œ

ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê³  NFR(Non-Functional Requirements) ë‹¬ì„± ì—¬ë¶€ë¥¼ ê²€ì¦

---

## ğŸ“ ì„±ëŠ¥ ëª©í‘œ (NFR)

- **ì‘ë‹µ ì‹œê°„**: P95 < 30ì´ˆ
- **ë™ì‹œ ì‚¬ìš©ì**: 100ëª… ì²˜ë¦¬ ê°€ëŠ¥
- **ì—ëŸ¬ìœ¨**: < 1%
- **ì²˜ë¦¬ëŸ‰**: ìµœì†Œ 10 req/sec

---

## ğŸ—ï¸ í…ŒìŠ¤íŠ¸ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Performance Testing Architecture                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Load Generator (Locust)                 â”‚                â”‚
â”‚  â”‚  - ê°€ìƒ ì‚¬ìš©ì ìƒì„±                        â”‚                â”‚
â”‚  â”‚  - ë™ì‹œ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜                    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                     â”‚                                          â”‚
â”‚                     â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Test Scenarios                           â”‚                â”‚
â”‚  â”‚  - ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸ (100íšŒ)                â”‚                â”‚
â”‚  â”‚  - ë™ì‹œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ (100ëª…)              â”‚                â”‚
â”‚  â”‚  - ë¶€í•˜ í…ŒìŠ¤íŠ¸ (ì¦ê°€ íŒ¨í„´)                 â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                     â”‚                                          â”‚
â”‚                     â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Backend API                              â”‚                â”‚
â”‚  â”‚  (FastAPI + PostgreSQL + Milvus)         â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                     â”‚                                          â”‚
â”‚                     â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Metrics Collection                       â”‚                â”‚
â”‚  â”‚  - Response Times (P50, P95, P99)        â”‚                â”‚
â”‚  â”‚  - Error Rates                            â”‚                â”‚
â”‚  â”‚  - Throughput (req/sec)                  â”‚                â”‚
â”‚  â”‚  - Resource Usage (CPU, Memory)          â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                     â”‚                                          â”‚
â”‚                     â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  Performance Report                       â”‚                â”‚
â”‚  â”‚  - HTML Report (Graphs)                  â”‚                â”‚
â”‚  â”‚  - CSV Data                              â”‚                â”‚
â”‚  â”‚  - JSON Results                          â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ êµ¬í˜„ ê³„íš

### Phase 1: Locust ì„¤ì • (0.5ì‹œê°„)

#### 1.1 Locust ì„¤ì¹˜
**íŒŒì¼**: `backend/requirements-dev.txt`
```python
locust==2.16.1
```

```bash
pip install locust
```

#### 1.2 Locust íŒŒì¼ ì‘ì„±
**íŒŒì¼**: `backend/tests/performance/locustfile.py`
```python
"""
ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

ëª©í‘œ:
- P95 ì‘ë‹µ ì‹œê°„ < 30ì´ˆ
- ë™ì‹œ ì‚¬ìš©ì 100ëª… ì²˜ë¦¬
- ì—ëŸ¬ìœ¨ < 1%
"""
from locust import HttpUser, task, between
import random


class RAGPlatformUser(HttpUser):
    """RAG í”Œë«í¼ ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜"""

    wait_time = between(1, 3)  # 1-3ì´ˆ ëŒ€ê¸°
    host = "http://localhost:8000"

    def on_start(self):
        """í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œ ë¡œê·¸ì¸"""
        # ë¡œê·¸ì¸í•˜ì—¬ í† í° ì–»ê¸°
        response = self.client.post(
            "/api/v1/auth/login",
            json={
                "email": "user@example.com",
                "password": "password123"
            }
        )

        if response.status_code == 200:
            data = response.json()
            self.token = data.get("access_token")
        else:
            raise Exception("Login failed")

    @task(10)
    def search_query(self):
        """ê²€ìƒ‰ ì¿¼ë¦¬ (ê°€ì¥ ë¹ˆë²ˆí•œ ì‘ì—…)"""
        queries = [
            "ì—°ì°¨ ì‚¬ìš© ë°©ë²•",
            "íœ´ê°€ ì‹ ì²­ ì ˆì°¨",
            "ê¸‰ì—¬ ì§€ê¸‰ì¼",
            "ì¶œí‡´ê·¼ ì‹œê°„",
            "íšŒì˜ì‹¤ ì˜ˆì•½ ë°©ë²•",
            "ë³µì§€ ì œë„",
            "ì¬íƒ ê·¼ë¬´ ì •ì±…",
            "êµìœ¡ ì§€ì› ì œë„",
        ]

        query = random.choice(queries)

        self.client.post(
            "/api/v1/search/",
            json={"query": query, "limit": 5},
            headers={"Authorization": f"Bearer {self.token}"},
            name="/api/v1/search/ (ê²€ìƒ‰)"
        )

    @task(3)
    def view_history(self):
        """íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        self.client.get(
            "/api/v1/users/me/history?page=1&page_size=10",
            headers={"Authorization": f"Bearer {self.token}"},
            name="/api/v1/users/me/history (íˆìŠ¤í† ë¦¬)"
        )

    @task(1)
    def submit_feedback(self):
        """í”¼ë“œë°± ì œì¶œ"""
        self.client.post(
            "/api/v1/feedback/",
            json={
                "query_id": "test_query_123",
                "rating": random.randint(1, 5),
                "comment": "í…ŒìŠ¤íŠ¸ í”¼ë“œë°±"
            },
            headers={"Authorization": f"Bearer {self.token}"},
            name="/api/v1/feedback/ (í”¼ë“œë°±)"
        )
```

---

### Phase 2: ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸ (1ì‹œê°„)

#### 2.1 ì‘ë‹µ ì‹œê°„ ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸
**íŒŒì¼**: `backend/tests/performance/test_response_time.py`
```python
"""
ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸

ëª©í‘œ: P95 < 30ì´ˆ
"""
import asyncio
import httpx
import statistics
import time
from typing import List


async def measure_search_response_time() -> List[float]:
    """
    100íšŒ ê²€ìƒ‰ ìš”ì²­ ì‹¤í–‰ ë° ì‘ë‹µ ì‹œê°„ ì¸¡ì •

    Returns:
        List[float]: ì‘ë‹µ ì‹œê°„ ë¦¬ìŠ¤íŠ¸ (ms)
    """
    # ë¡œê·¸ì¸
    async with httpx.AsyncClient(base_url="http://localhost:8000") as client:
        login_response = await client.post(
            "/api/v1/auth/login",
            json={
                "email": "user@example.com",
                "password": "password123"
            }
        )
        token = login_response.json()["access_token"]

        # 100íšŒ ê²€ìƒ‰ ìš”ì²­
        response_times = []
        test_queries = [
            "ì—°ì°¨ ì‚¬ìš© ë°©ë²•",
            "íœ´ê°€ ì‹ ì²­ ì ˆì°¨",
            "ê¸‰ì—¬ ì§€ê¸‰ì¼",
            "ì¶œí‡´ê·¼ ì‹œê°„",
            "íšŒì˜ì‹¤ ì˜ˆì•½",
        ]

        for i in range(100):
            query = test_queries[i % len(test_queries)]

            start_time = time.time()

            response = await client.post(
                "/api/v1/search/",
                json={"query": query, "limit": 5},
                headers={"Authorization": f"Bearer {token}"},
                timeout=60.0
            )

            end_time = time.time()
            duration_ms = (end_time - start_time) * 1000

            response_times.append(duration_ms)

            if (i + 1) % 10 == 0:
                print(f"Progress: {i + 1}/100")

        return response_times


def calculate_percentiles(data: List[float]) -> dict:
    """
    ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°

    Args:
        data: ì‘ë‹µ ì‹œê°„ ë¦¬ìŠ¤íŠ¸

    Returns:
        dict: P50, P95, P99
    """
    sorted_data = sorted(data)

    return {
        "p50": statistics.median(sorted_data),
        "p95": sorted_data[int(len(sorted_data) * 0.95)],
        "p99": sorted_data[int(len(sorted_data) * 0.99)],
        "min": min(sorted_data),
        "max": max(sorted_data),
        "mean": statistics.mean(sorted_data),
    }


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=== ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    print("100íšŒ ê²€ìƒ‰ ìš”ì²­ ì‹¤í–‰ ì¤‘...\n")

    response_times = await measure_search_response_time()

    print("\n=== ê²°ê³¼ ===")
    percentiles = calculate_percentiles(response_times)

    for key, value in percentiles.items():
        print(f"{key.upper()}: {value:.2f} ms ({value/1000:.2f} s)")

    # NFR ê²€ì¦
    p95_seconds = percentiles["p95"] / 1000
    if p95_seconds < 30:
        print(f"\nâœ“ P95 ì‘ë‹µ ì‹œê°„ ëª©í‘œ ë‹¬ì„±: {p95_seconds:.2f}s < 30s")
    else:
        print(f"\nâœ— P95 ì‘ë‹µ ì‹œê°„ ëª©í‘œ ë¯¸ë‹¬: {p95_seconds:.2f}s >= 30s")

    # CSV ì €ì¥
    import csv
    with open("response_times.csv", "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["request_number", "response_time_ms"])
        for i, rt in enumerate(response_times, 1):
            writer.writerow([i, rt])

    print("\nê²°ê³¼ê°€ response_times.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(main())
```

**ì‹¤í–‰**:
```bash
python backend/tests/performance/test_response_time.py
```

---

### Phase 3: ë™ì‹œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ (1ì‹œê°„)

#### 3.1 Locust ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
**íŒŒì¼**: `backend/scripts/run_load_test.sh`
```bash
#!/bin/bash
# Locust ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

echo "=== Locust ë¶€í•˜ í…ŒìŠ¤íŠ¸ ==="
echo "ëª©í‘œ: ë™ì‹œ ì‚¬ìš©ì 100ëª…, ì—ëŸ¬ìœ¨ < 1%"
echo ""

# ë°±ì—”ë“œ ì„œë²„ í™•ì¸
if ! curl -s http://localhost:8000/health > /dev/null; then
    echo "âœ— ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
    echo "docker-compose up -dë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”"
    exit 1
fi

echo "âœ“ ë°±ì—”ë“œ ì„œë²„ ì •ìƒ"
echo ""

# Locust ì‹¤í–‰ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ)
locust \
    -f backend/tests/performance/locustfile.py \
    --headless \
    --users 100 \
    --spawn-rate 10 \
    --run-time 5m \
    --html=load-test-report.html \
    --csv=load-test \
    --host=http://localhost:8000

echo ""
echo "=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ==="
echo "ë¦¬í¬íŠ¸: load-test-report.html"
echo "ë°ì´í„°: load-test_stats.csv"
```

**ì‹¤í–‰**:
```bash
bash backend/scripts/run_load_test.sh
```

#### 3.2 Locust ì›¹ UI ëª¨ë“œ
```bash
# ì›¹ UIë¡œ ì‹¤í–‰ (ëŒ€í™”í˜•)
locust -f backend/tests/performance/locustfile.py

# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8089 ì ‘ì†
# ì‚¬ìš©ì ìˆ˜ì™€ ì¦ê°€ìœ¨ ì„¤ì •
```

---

### Phase 4: ì„±ëŠ¥ ë¶„ì„ ë° ë¦¬í¬íŠ¸ (0.5ì‹œê°„)

#### 4.1 ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
**íŒŒì¼**: `backend/tests/performance/analyze_results.py`
```python
"""
ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„
"""
import csv
import json


def analyze_locust_results(stats_file: str) -> dict:
    """
    Locust í†µê³„ íŒŒì¼ ë¶„ì„

    Args:
        stats_file: CSV í†µê³„ íŒŒì¼ ê²½ë¡œ

    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    with open(stats_file, "r") as f:
        reader = csv.DictReader(f)
        rows = list(reader)

    # ì „ì²´ í†µê³„ (ë§ˆì§€ë§‰ Aggregated í–‰)
    aggregated = [r for r in rows if r["Name"] == "Aggregated"][0]

    total_requests = int(aggregated["Request Count"])
    total_failures = int(aggregated["Failure Count"])
    error_rate = (total_failures / total_requests * 100) if total_requests > 0 else 0

    return {
        "total_requests": total_requests,
        "total_failures": total_failures,
        "error_rate_percent": error_rate,
        "p50_ms": float(aggregated["50%"]),
        "p95_ms": float(aggregated["95%"]),
        "p99_ms": float(aggregated["99%"]),
        "requests_per_second": float(aggregated["Requests/s"]),
    }


def generate_report(results: dict):
    """
    ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±

    Args:
        results: ë¶„ì„ ê²°ê³¼
    """
    print("=" * 60)
    print("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸")
    print("=" * 60)
    print()

    print(f"ì´ ìš”ì²­ ìˆ˜: {results['total_requests']:,}")
    print(f"ì‹¤íŒ¨ ìˆ˜: {results['total_failures']:,}")
    print(f"ì—ëŸ¬ìœ¨: {results['error_rate_percent']:.2f}%")
    print()

    print("ì‘ë‹µ ì‹œê°„:")
    print(f"  P50: {results['p50_ms']:.0f} ms ({results['p50_ms']/1000:.2f} s)")
    print(f"  P95: {results['p95_ms']:.0f} ms ({results['p95_ms']/1000:.2f} s)")
    print(f"  P99: {results['p99_ms']:.0f} ms ({results['p99_ms']/1000:.2f} s)")
    print()

    print(f"ì²˜ë¦¬ëŸ‰: {results['requests_per_second']:.2f} req/s")
    print()

    # NFR ê²€ì¦
    print("=" * 60)
    print("NFR ê²€ì¦")
    print("=" * 60)

    nfr_passed = True

    # P95 < 30ì´ˆ
    p95_seconds = results['p95_ms'] / 1000
    if p95_seconds < 30:
        print(f"âœ“ P95 ì‘ë‹µ ì‹œê°„: {p95_seconds:.2f}s < 30s")
    else:
        print(f"âœ— P95 ì‘ë‹µ ì‹œê°„: {p95_seconds:.2f}s >= 30s")
        nfr_passed = False

    # ì—ëŸ¬ìœ¨ < 1%
    if results['error_rate_percent'] < 1:
        print(f"âœ“ ì—ëŸ¬ìœ¨: {results['error_rate_percent']:.2f}% < 1%")
    else:
        print(f"âœ— ì—ëŸ¬ìœ¨: {results['error_rate_percent']:.2f}% >= 1%")
        nfr_passed = False

    # ì²˜ë¦¬ëŸ‰ >= 10 req/s
    if results['requests_per_second'] >= 10:
        print(f"âœ“ ì²˜ë¦¬ëŸ‰: {results['requests_per_second']:.2f} >= 10 req/s")
    else:
        print(f"âœ— ì²˜ë¦¬ëŸ‰: {results['requests_per_second']:.2f} < 10 req/s")
        nfr_passed = False

    print()
    if nfr_passed:
        print("âœ“ ëª¨ë“  NFR ëª©í‘œ ë‹¬ì„±")
    else:
        print("âœ— ì¼ë¶€ NFR ëª©í‘œ ë¯¸ë‹¬")

    # JSON ì €ì¥
    with open("performance_summary.json", "w") as f:
        json.dump(results, f, indent=2)

    print()
    print("ìƒì„¸ ê²°ê³¼ê°€ performance_summary.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python analyze_results.py <stats_file.csv>")
        sys.exit(1)

    stats_file = sys.argv[1]
    results = analyze_locust_results(stats_file)
    generate_report(results)
```

**ì‹¤í–‰**:
```bash
python backend/tests/performance/analyze_results.py load-test_stats.csv
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
**ëª©í‘œ**: P95 < 30ì´ˆ

```bash
# ì‹¤í–‰
python backend/tests/performance/test_response_time.py

# ì˜ˆìƒ ê²°ê³¼
# P50: 15,000 ms (15 s)
# P95: 25,000 ms (25 s)  â† ëª©í‘œ ë‹¬ì„±
# P99: 28,000 ms (28 s)
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë™ì‹œ ì‚¬ìš©ì 100ëª…
**ëª©í‘œ**: ì—ëŸ¬ìœ¨ < 1%

```bash
# ì‹¤í–‰ (5ë¶„ê°„)
bash backend/scripts/run_load_test.sh

# ì˜ˆìƒ ê²°ê³¼
# ì´ ìš”ì²­: 3,000
# ì‹¤íŒ¨: 15
# ì—ëŸ¬ìœ¨: 0.5%  â† ëª©í‘œ ë‹¬ì„±
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë¨í”„ì—… í…ŒìŠ¤íŠ¸
**ëª©í‘œ**: ì ì§„ì  ë¶€í•˜ ì¦ê°€ ì‹œ ì•ˆì •ì„± í™•ì¸

```bash
# ì›¹ UIë¡œ ì‹¤í–‰
locust -f backend/tests/performance/locustfile.py

# ì„¤ì •:
# - ì‚¬ìš©ì: 200
# - ì¦ê°€ìœ¨: 5/sec
# - ì‹¤í–‰ ì‹œê°„: 10ë¶„

# í™•ì¸ ì‚¬í•­:
# - ì‚¬ìš©ì ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ ì‘ë‹µ ì‹œê°„ ì¶”ì´
# - ì„ê³„ì  í™•ì¸ (ì‘ë‹µ ì‹œê°„ì´ ê¸‰ê²©íˆ ì¦ê°€í•˜ëŠ” ì§€ì )
```

---

## âœ… ê²€ì¦ ê¸°ì¤€

### ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„±
- [ ] **P95 ì‘ë‹µ ì‹œê°„ < 30ì´ˆ**
  - 100íšŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  - 95íšŒ ì´ìƒ 30ì´ˆ ì´ë‚´

- [ ] **ë™ì‹œ ì‚¬ìš©ì 100ëª… ì²˜ë¦¬**
  - 5ë¶„ê°„ ì•ˆì •ì  ì²˜ë¦¬
  - ì—ëŸ¬ìœ¨ < 1%

- [ ] **ì²˜ë¦¬ëŸ‰ >= 10 req/s**
  - ì§€ì† ê°€ëŠ¥í•œ ì²˜ë¦¬ëŸ‰

### ë¦¬í¬íŠ¸ ìƒì„±
- [ ] HTML ë¦¬í¬íŠ¸ (ê·¸ë˜í”„ í¬í•¨)
- [ ] CSV ë°ì´í„° (ìƒì„¸ ë¶„ì„ìš©)
- [ ] JSON ìš”ì•½ (CI/CD ì—°ë™ìš©)

---

## ğŸ“‚ íŒŒì¼ êµ¬ì¡°

```
backend/
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ performance/
â”‚       â”œâ”€â”€ locustfile.py
â”‚       â”œâ”€â”€ test_response_time.py
â”‚       â””â”€â”€ analyze_results.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_load_test.sh
â””â”€â”€ performance-reports/        # ì„±ëŠ¥ ë¦¬í¬íŠ¸ (gitignore)
    â”œâ”€â”€ load-test-report.html
    â”œâ”€â”€ load-test_stats.csv
    â”œâ”€â”€ response_times.csv
    â””â”€â”€ performance_summary.json
```

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### ì‘ë‹µ ì‹œê°„ ë¶„í¬
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response Time Distribution            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  P50:  15.2s  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘    â”‚
â”‚  P75:  20.5s  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘    â”‚
â”‚  P90:  24.8s  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘    â”‚
â”‚  P95:  27.1s  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘    â”‚
â”‚  P99:  29.3s  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚
â”‚  Max:  32.5s  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë¶€í•˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load Test Summary                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Duration: 5 minutes                   â”‚
â”‚  Users: 100 (concurrent)               â”‚
â”‚  Total Requests: 3,245                 â”‚
â”‚  Failures: 18                          â”‚
â”‚  Error Rate: 0.55%  âœ“                  â”‚
â”‚  Requests/sec: 10.8  âœ“                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ ì„±ëŠ¥ ìµœì í™” íŒ

### ë³‘ëª© ì§€ì  ì‹ë³„
1. **ë²¡í„° ê²€ìƒ‰ ëŠë¦¼** (> 2ì´ˆ)
   - HNSW íŒŒë¼ë¯¸í„° ì¡°ì • (ef: 64 â†’ 32)
   - ì¸ë±ìŠ¤ ì¬êµ¬ì„±

2. **LLM í˜¸ì¶œ ëŠë¦¼** (> 25ì´ˆ)
   - Ollama â†’ OpenAI ì „í™˜ (3ë°° ë¹ ë¦„)
   - í”„ë¡¬í”„íŠ¸ ìµœì í™” (í† í° ì ˆì•½)

3. **DB ì¿¼ë¦¬ ëŠë¦¼** (> 1ì´ˆ)
   - Connection Pool ì¦ê°€
   - ì¸ë±ìŠ¤ ì¶”ê°€
   - ì¿¼ë¦¬ ìµœì í™”

### ìºì‹± ì „ëµ
```python
# ê²€ìƒ‰ ê²°ê³¼ ìºì‹± (Redis)
from functools import lru_cache

@lru_cache(maxsize=100)
def get_cached_search_result(query: str):
    # ë™ì¼ ê²€ìƒ‰ì–´ ìºì‹±
    pass
```

---

## ğŸ”„ í–¥í›„ ê°œì„  ì‚¬í•­

### Phase 4 ì´í›„
1. **ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸**
   - ì‹œìŠ¤í…œ í•œê³„ í…ŒìŠ¤íŠ¸
   - 200ëª…, 500ëª…, 1000ëª…

2. **Soak í…ŒìŠ¤íŠ¸**
   - ì¥ì‹œê°„ ë¶€í•˜ í…ŒìŠ¤íŠ¸ (24ì‹œê°„)
   - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸

3. **ìŠ¤íŒŒì´í¬ í…ŒìŠ¤íŠ¸**
   - ê¸‰ê²©í•œ ë¶€í•˜ ì¦ê°€ ì‹œë®¬ë ˆì´ì…˜
   - Auto-scaling ê²€ì¦

4. **ë¶„ì‚° ë¶€í•˜ í…ŒìŠ¤íŠ¸**
   - ì—¬ëŸ¬ ë¨¸ì‹ ì—ì„œ ë™ì‹œ í…ŒìŠ¤íŠ¸
   - Locust Master-Worker ëª¨ë“œ

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Locust Documentation](https://docs.locust.io/)
- [Performance Testing Best Practices](https://martinfowler.com/articles/practical-test-pyramid.html#PerformanceTests)
- [HTTP Load Testing](https://github.com/rakyll/hey)

---

**ì‘ì„±ì**: Task Planner
**ì‘ì„±ì¼**: 2026-01-10
**ë²„ì „**: 1.0.0
