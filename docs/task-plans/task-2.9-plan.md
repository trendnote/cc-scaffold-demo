# Task 2.9: ì„±ëŠ¥ ìµœì í™” ë° ë¡œê¹… - ì‹¤í–‰ ê³„íš

---

## ğŸ“‹ Meta

- **Task ID**: 2.9
- **Taskëª…**: ì„±ëŠ¥ ìµœì í™” ë° ë¡œê¹…
- **ì˜ˆìƒ ì‹œê°„**: 4ì‹œê°„
- **ë‹´ë‹¹**: Backend
- **ì‘ì„±ì¼**: 2026-01-03
- **ìƒíƒœ**: Ready for Implementation
- **ë²„ì „**: 1.0.0

---

## 1. Executive Summary

### 1.1 ëª©í‘œ
ì „ì²´ ê²€ìƒ‰ í”Œë¡œìš°ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•˜ê³  êµ¬ì¡°í™”ëœ ë¡œê¹…ì„ êµ¬í˜„í•˜ì—¬ P95 < 30ì´ˆ ëª©í‘œë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.

### 1.2 í•µì‹¬ ìš”êµ¬ì‚¬í•­
- **ì„±ëŠ¥**: [HARD RULE] P95 < 30ì´ˆ (ë²¡í„° ê²€ìƒ‰ < 1ì´ˆ, LLM < 25ì´ˆ, DB < 0.5ì´ˆ)
- **ë¡œê¹…**: [HARD RULE] ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹, structlog ì‚¬ìš©
- **ìµœì í™”**: DB Connection Pool, ë¹„ë™ê¸° ì²˜ë¦¬
- **ëª¨ë‹ˆí„°ë§**: ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§, ë³‘ëª© ì§€ì  íŒŒì•…

### 1.3 ì„±ê³µ ê¸°ì¤€
- [ ] P95 < 30ì´ˆ ë‹¬ì„±
- [ ] êµ¬ì¡°í™”ëœ ë¡œê¹… (JSON í¬ë§·)
- [ ] DB Connection Pool ì„¤ì • (pool_size=20)
- [ ] ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”
- [ ] ì„±ëŠ¥ ì¸¡ì • ë¦¬í¬íŠ¸ ì‘ì„±

### 1.4 Why This Task Matters
**í”„ë¡œë•ì…˜ ì¤€ë¹„**:
- **ì‚¬ìš©ì ê²½í—˜**: ë¹ ë¥¸ ì‘ë‹µ ì†ë„ë¡œ ë§Œì¡±ë„ í–¥ìƒ
- **ìš´ì˜ íš¨ìœ¨**: êµ¬ì¡°í™”ëœ ë¡œê·¸ë¡œ ë¬¸ì œ í•´ê²° ì‹œê°„ ë‹¨ì¶•
- **í™•ì¥ì„±**: ìµœì í™”ëœ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥

---

## 2. ì„ í–‰ ì¡°ê±´ ê²€ì¦

### 2.1 í™˜ê²½ ê²€ì¦
```bash
# Task 2.6 ì™„ë£Œ í™•ì¸ (ì„±ëŠ¥ ì¸¡ì • ê¸°ë³¸ êµ¬ì¡°)
ls -la backend/app/utils/timer.py

# Structlog ì„¤ì¹˜ í™•ì¸
python -c "import structlog; print(structlog.__version__)"
```

### 2.2 ì˜ì¡´ì„± í™•ì¸
- [x] **Task 2.6**: ì„±ëŠ¥ ì¸¡ì • ê¸°ë³¸ êµ¬ì¡° ì™„ë£Œ
- [ ] **requirements.txt**: structlog, python-json-logger

---

## 3. ì„±ëŠ¥ ëª©í‘œ

### 3.1 ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ ëª©í‘œ

| ì»´í¬ë„ŒíŠ¸ | P95 ëª©í‘œ | ì„¤ëª… |
|----------|----------|------|
| ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± | < 500ms | Ollama nomic-embed-text |
| Milvus ë²¡í„° ê²€ìƒ‰ | < 1ì´ˆ | HNSW ê²€ìƒ‰ (ef=64) |
| LLM ë‹µë³€ ìƒì„± | < 25ì´ˆ | Ollama llama3 ë˜ëŠ” OpenAI |
| DB ì €ì¥ | < 500ms | PostgreSQL ì“°ê¸° |
| **ì „ì²´** | **< 30ì´ˆ** | End-to-End ì‘ë‹µ |

### 3.2 ìµœì í™” ì „ëµ

```
ì„±ëŠ¥ ìµœì í™” ìš°ì„ ìˆœìœ„:

1. LLM í˜¸ì¶œ ìµœì í™” (ê°€ì¥ ëŠë¦° ë¶€ë¶„)
   - íƒ€ì„ì•„ì›ƒ 30ì´ˆ
   - ì¬ì‹œë„ ë¡œì§ ê°œì„ 

2. DB Connection Pooling
   - SQLAlchemy pool_size=20
   - pool_recycle=3600

3. ë¹„ë™ê¸° ì²˜ë¦¬
   - async/await í™œìš©
   - ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë¶€ë¶„ ì‹ë³„

4. Caching (ì„ íƒì )
   - ë™ì¼ ì¿¼ë¦¬ 1ì‹œê°„ ìºì‹±
   - Redis ë˜ëŠ” ë©”ëª¨ë¦¬ ìºì‹œ
```

---

## 4. êµ¬í˜„ ë‹¨ê³„ë³„ ìƒì„¸ ê³„íš

### 4.1 Step 1: êµ¬ì¡°í™”ëœ ë¡œê¹… (90ë¶„)

#### ì‘ì—… ë‚´ìš©
**`backend/app/utils/logger.py` ì‘ì„±**:

```python
import structlog
import logging
import sys
from typing import Any, Dict


def configure_logging(log_level: str = "INFO"):
    """
    Structlog êµ¬ì¡°í™”ëœ ë¡œê¹… ì„¤ì •

    [HARD RULE] ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹:
    - user_id: ë’¤ 4ìë¦¬ë§Œ í‘œì‹œ
    - email: @ ì• 2ìë§Œ í‘œì‹œ
    - query: ë¯¼ê° í‚¤ì›Œë“œ ë§ˆìŠ¤í‚¹
    """
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            _mask_sensitive_data,  # ì»¤ìŠ¤í…€ í”„ë¡œì„¸ì„œ
            structlog.processors.JSONRenderer()
        ],
        wrapper_class=structlog.make_filtering_bound_logger(
            logging.getLevelName(log_level)
        ),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(file=sys.stdout),
        cache_logger_on_first_use=True,
    )


def _mask_sensitive_data(logger, method_name, event_dict: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ í”„ë¡œì„¸ì„œ

    [HARD RULE] ë§ˆìŠ¤í‚¹ ëŒ€ìƒ:
    - user_id: user_1234 â†’ user_****1234
    - email: user@example.com â†’ us**@example.com
    - query: ë¯¼ê° í‚¤ì›Œë“œ (ì£¼ë¯¼ë²ˆí˜¸, ê³„ì¢Œë²ˆí˜¸ íŒ¨í„´)
    """
    import re

    # user_id ë§ˆìŠ¤í‚¹
    if "user_id" in event_dict:
        user_id = event_dict["user_id"]
        if len(user_id) > 4:
            event_dict["user_id"] = f"{user_id[:-4].replace(user_id[:-4], '****')}{user_id[-4:]}"

    # email ë§ˆìŠ¤í‚¹
    if "email" in event_dict:
        email = event_dict["email"]
        if "@" in email:
            local, domain = email.split("@")
            masked_local = local[:2] + "**" if len(local) > 2 else "**"
            event_dict["email"] = f"{masked_local}@{domain}"

    # query ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹
    if "query" in event_dict:
        query = event_dict["query"]

        # ì£¼ë¯¼ë²ˆí˜¸ íŒ¨í„´ (123456-1234567)
        query = re.sub(r"\d{6}-\d{7}", "[ì£¼ë¯¼ë²ˆí˜¸]", query)

        # ê³„ì¢Œë²ˆí˜¸ íŒ¨í„´ (123-456-789012)
        query = re.sub(r"\d{3}-\d{3}-\d{6,}", "[ê³„ì¢Œë²ˆí˜¸]", query)

        # ì „í™”ë²ˆí˜¸ íŒ¨í„´ (010-1234-5678)
        query = re.sub(r"\d{3}-\d{4}-\d{4}", "[ì „í™”ë²ˆí˜¸]", query)

        event_dict["query"] = query

    return event_dict


def get_logger(name: str):
    """
    êµ¬ì¡°í™”ëœ ë¡œê±° ìƒì„±

    Usage:
        logger = get_logger(__name__)
        logger.info(
            "search_request",
            user_id="user_12345",
            query="ì—°ì°¨ ì‚¬ìš© ë°©ë²•",
            response_time_ms=1234
        )
    """
    return structlog.get_logger(name)
```

---

### 4.2 Step 2: DB Connection Pool ìµœì í™” (30ë¶„)

#### ì‘ì—… ë‚´ìš©
**`backend/app/db/session.py` ìˆ˜ì •**:

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.core.config import settings

# DB Connection Pool ì„¤ì •
engine = create_engine(
    settings.DATABASE_URL,
    pool_size=20,             # ìµœëŒ€ 20ê°œ ì—°ê²°
    max_overflow=10,          # ì¶”ê°€ 10ê°œ overflow
    pool_recycle=3600,        # 1ì‹œê°„ë§ˆë‹¤ ì—°ê²° ì¬ìƒì„±
    pool_pre_ping=True,       # ì—°ê²° ìœ íš¨ì„± ì‚¬ì „ í™•ì¸
    echo=False                # SQL ë¡œê·¸ ë¹„í™œì„±í™” (ì„±ëŠ¥)
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


def get_db():
    """DB ì„¸ì…˜ ì˜ì¡´ì„±"""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

---

### 4.3 Step 3: ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ (90ë¶„)

#### ì‘ì—… ë‚´ìš©
**`backend/tests/performance/test_search_performance.py` ì‘ì„±**:

```python
import time
import statistics
from app.services.search_service import SearchService
from app.utils.timer import PerformanceTimer
import pytest


@pytest.mark.performance
def test_search_performance_100_requests():
    """
    100íšŒ ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •

    ëª©í‘œ:
    - P50: < 10ì´ˆ
    - P95: < 30ì´ˆ
    - P99: < 40ì´ˆ
    """
    search_service = SearchService()

    queries = [
        "ì—°ì°¨ ì‚¬ìš© ë°©ë²•",
        "ê¸‰ì—¬ ì§€ê¸‰ì¼",
        "íšŒì˜ì‹¤ ì˜ˆì•½",
        "ì¬íƒê·¼ë¬´ ì •ì±…",
        "ê²½ì¡°ì‚¬ íœ´ê°€"
    ] * 20  # 100ê°œ ì¿¼ë¦¬

    total_times = []
    embedding_times = []
    search_times = []
    llm_times = []

    for query in queries:
        timer = PerformanceTimer()

        # ê²€ìƒ‰ ìˆ˜í–‰
        response = search_service.search(
            query=query,
            limit=5,
            timer=timer
        )

        # ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
        total_times.append(timer.get_total())
        embedding_times.append(timer.get("embedding"))
        search_times.append(timer.get("search"))
        llm_times.append(timer.get("llm"))

    # í†µê³„ ê³„ì‚°
    def calculate_percentiles(data):
        p50 = statistics.median(data)
        p95 = statistics.quantiles(data, n=20)[18]  # 95th
        p99 = statistics.quantiles(data, n=100)[98]  # 99th
        return p50, p95, p99

    total_p50, total_p95, total_p99 = calculate_percentiles(total_times)
    emb_p50, emb_p95, emb_p99 = calculate_percentiles(embedding_times)
    search_p50, search_p95, search_p99 = calculate_percentiles(search_times)
    llm_p50, llm_p95, llm_p99 = calculate_percentiles(llm_times)

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n=== ì„±ëŠ¥ ì¸¡ì • ê²°ê³¼ (100íšŒ) ===")
    print(f"Total - P50: {total_p50:.0f}ms, P95: {total_p95:.0f}ms, P99: {total_p99:.0f}ms")
    print(f"Embedding - P50: {emb_p50:.0f}ms, P95: {emb_p95:.0f}ms, P99: {emb_p99:.0f}ms")
    print(f"Search - P50: {search_p50:.0f}ms, P95: {search_p95:.0f}ms, P99: {search_p99:.0f}ms")
    print(f"LLM - P50: {llm_p50:.0f}ms, P95: {llm_p95:.0f}ms, P99: {llm_p99:.0f}ms")

    # [HARD RULE] P95 < 30ì´ˆ ê²€ì¦
    assert total_p95 < 30000, f"P95 ì„±ëŠ¥ ëª©í‘œ ë¯¸ë‹¬: {total_p95:.0f}ms"

    # ì»´í¬ë„ŒíŠ¸ë³„ ëª©í‘œ ê²€ì¦
    assert emb_p95 < 500, f"Embedding P95 ëª©í‘œ ë¯¸ë‹¬: {emb_p95:.0f}ms"
    assert search_p95 < 1000, f"Search P95 ëª©í‘œ ë¯¸ë‹¬: {search_p95:.0f}ms"
    assert llm_p95 < 25000, f"LLM P95 ëª©í‘œ ë¯¸ë‹¬: {llm_p95:.0f}ms"
```

---

### 4.4 Step 4: ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™” (60ë¶„)

#### ì‘ì—… ë‚´ìš©
**`backend/app/main.py` Uvicorn ì„¤ì •**:

```python
# uvicorn ì‹¤í–‰ ì‹œ workers ì„¤ì •
# uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4

# ë˜ëŠ” gunicorn + uvicorn
# gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

**ë¹„ë™ê¸° API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸**:

```python
# backend/app/routers/search.py
@router.post("/")
async def search(request: SearchQueryRequest):
    # async/await ì‚¬ìš© í™•ì¸
    pass
```

---

## 5. ì„±ëŠ¥ ì¸¡ì • ë¦¬í¬íŠ¸ ì‘ì„±

### 5.1 ë¦¬í¬íŠ¸ êµ¬ì¡°

**`docs/performance-report.md` ì‘ì„±**:

```markdown
# ì„±ëŠ¥ ì¸¡ì • ë¦¬í¬íŠ¸

## ì¸¡ì • í™˜ê²½
- CPU: [ì‚¬ì–‘]
- RAM: [ìš©ëŸ‰]
- OS: macOS / Linux
- Python: 3.12.3
- Ollama: llama3

## ì¸¡ì • ê²°ê³¼

| ì»´í¬ë„ŒíŠ¸ | P50 | P95 | P99 | ëª©í‘œ | ë‹¬ì„± |
|----------|-----|-----|-----|------|------|
| ì¿¼ë¦¬ ì„ë² ë”© | 120ms | 450ms | 600ms | < 500ms | âœ… |
| ë²¡í„° ê²€ìƒ‰ | 350ms | 800ms | 1100ms | < 1ì´ˆ | âœ… |
| LLM ë‹µë³€ ìƒì„± | 2300ms | 23000ms | 28000ms | < 25ì´ˆ | âœ… |
| ì „ì²´ | 2800ms | 24500ms | 29800ms | < 30ì´ˆ | âœ… |

## ë³‘ëª© ì§€ì 

1. **LLM ë‹µë³€ ìƒì„±** (ê°€ì¥ ëŠë¦¼)
   - P95: 23ì´ˆ
   - ìµœì í™”: OpenAIë¡œ ì „í™˜ ê³ ë ¤

2. **ë²¡í„° ê²€ìƒ‰**
   - P95: 800ms
   - ìµœì í™”: Milvus ì¸ë±ìŠ¤ íŠœë‹

## ê¶Œì¥ ì‚¬í•­

1. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” OpenAI GPT-4 ì‚¬ìš© ê¶Œì¥
2. Milvus HNSW íŒŒë¼ë¯¸í„° íŠœë‹ (ef 64 â†’ 128)
3. DB Connection Pool ëª¨ë‹ˆí„°ë§
```

---

## 6. ê²€ì¦ ê¸°ì¤€

### 6.1 í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] P95 < 30ì´ˆ ë‹¬ì„±
- [ ] êµ¬ì¡°í™”ëœ ë¡œê¹… (JSON í¬ë§·)
- [ ] ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹ (user_id, email, query)
- [ ] DB Connection Pool ì„¤ì • (pool_size=20)
- [ ] ë¹„ë™ê¸° ì²˜ë¦¬ í™•ì¸
- [ ] ì„±ëŠ¥ ì¸¡ì • ë¦¬í¬íŠ¸ ì‘ì„±

### 6.2 í’ˆì§ˆ ê¸°ì¤€

- [ ] ë¡œê·¸ JSON íŒŒì‹± ê°€ëŠ¥
- [ ] ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ë¬¸ì„œí™”

---

## 7. ì¶œë ¥ë¬¼

### 7.1 ìƒì„±ë  íŒŒì¼

1. `backend/app/utils/logger.py` - êµ¬ì¡°í™”ëœ ë¡œê¹…
2. `backend/tests/performance/test_search_performance.py` - ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
3. `docs/performance-report.md` - ì„±ëŠ¥ ì¸¡ì • ë¦¬í¬íŠ¸

### 7.2 ìˆ˜ì •ë  íŒŒì¼

1. `backend/app/db/session.py` - DB Connection Pool ì„¤ì •
2. `backend/app/main.py` - Structlog ì´ˆê¸°í™”
3. `backend/requirements.txt` - structlog, python-json-logger ì¶”ê°€

---

## 8. ì°¸ê³  ë¬¸ì„œ

- Task Breakdown: `docs/tasks/task-breakdown.md`
- Structlog: https://www.structlog.org/
- SQLAlchemy Pooling: https://docs.sqlalchemy.org/en/20/core/pooling.html

---

**ì‘ì„±ì**: Claude Code (Sonnet 4.5)
**ì‘ì„±ì¼**: 2026-01-03
